{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyONhcm5EcHE/R7Q5IrekhFs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/peterliujpdev/MNIST-Digit-Recognizer/blob/main/MNIST_Digit_Recognizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Math Intuition\n",
        "\n"
      ],
      "metadata": {
        "id": "j83-175Sty1X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Pytorch structure"
      ],
      "metadata": {
        "id": "WfTtXh4lxB5Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSAEmXEotYOK",
        "outputId": "eae957d0-f5d4-48bc-c642-f611a87d304a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimpleCNN(\n",
            "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=1600, out_features=128, bias=True)\n",
            "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        # 1. å·ç§¯å±‚ (Convolutional Layers)\n",
        "        # è¾“å…¥é€šé“ 1 (é»‘ç™½å›¾), è¾“å‡ºé€šé“ 32 (æå–32ç§ç‰¹å¾), å·ç§¯æ ¸ 3x3\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3)\n",
        "        # è¾“å…¥é€šé“ 32, è¾“å‡ºé€šé“ 64\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
        "\n",
        "        # 2. å…¨è¿æ¥å±‚ (Fully Connected Layers)\n",
        "        # è¿™é‡Œéœ€è¦ç®—ä¸€ä¸‹ç»´åº¦ï¼Œæˆ–è€…å…ˆè·‘ä¸€æ¬¡æŠ¥é”™çœ‹çœ‹å…·ä½“æ•°å­—ï¼Œé€šå¸¸æ˜¯ 64 * 5 * 5 æˆ–ç±»ä¼¼\n",
        "        self.fc1 = nn.Linear(64 * 5 * 5, 128)\n",
        "        self.fc2 = nn.Linear(128, 10) # æœ€åè¾“å‡º 10 ä¸ªæ•°å­— (0-9)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # ç¬¬ä¸€å±‚å·ç§¯ + æ¿€æ´»å‡½æ•°(ReLU) + æ± åŒ–(Pooling)\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2) # å›¾ç‰‡å˜å°ä¸€åŠ\n",
        "\n",
        "        # ç¬¬äºŒå±‚å·ç§¯\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2) # å›¾ç‰‡åˆå˜å°ä¸€åŠ\n",
        "\n",
        "        # å±•å¹³ (Flatten): æŠŠç«‹ä½“çš„æ•°æ®æ‹æ‰æˆä¸€ç»´å‘é‡ï¼Œå‡†å¤‡å–‚ç»™å…¨è¿æ¥å±‚\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        # å…¨è¿æ¥åˆ†ç±»\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        # è¾“å‡º Logits (æœªå½’ä¸€åŒ–çš„æ¦‚ç‡)\n",
        "        return x\n",
        "\n",
        "# å®ä¾‹åŒ–æ¨¡å‹\n",
        "model = SimpleCNN()\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "JbnEzufzxPvA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# ==========================================\n",
        "# ç¬¬ä¸€æ­¥ï¼šå‡†å¤‡æ•°æ® (Data Preparation)\n",
        "# ==========================================\n",
        "# å®šä¹‰ä¸€ä¸ªå˜æ¢ï¼šæŠŠå›¾ç‰‡å˜æˆ Tensor (çŸ©é˜µ)ï¼Œå¹¶å½’ä¸€åŒ– (è®©æ•°å€¼åœ¨ 0-1 ä¹‹é—´ï¼Œæ–¹ä¾¿è®¡ç®—)\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "# ä¸‹è½½è®­ç»ƒé›† (60,000 å¼ )\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "# ä¸‹è½½æµ‹è¯•é›† (10,000 å¼ )\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# å»ºç«‹åŠ è½½å™¨ (Batch Size = 64 æ„å‘³ç€æˆ‘ä»¬è¦ä¸€æ¬¡å¹¶è¡Œè®¡ç®— 64 å¼ å›¾ï¼Œåˆ©ç”¨çŸ©é˜µåŠ é€Ÿ)\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=1000, shuffle=False)\n",
        "\n",
        "# ==========================================\n",
        "# ç¬¬äºŒæ­¥ï¼šæ­å»ºæ¨¡å‹ (Model Architecture)\n",
        "# ==========================================\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        # å·ç§¯å±‚ï¼šæå–ç‰¹å¾ (è¿™å°±æ˜¯é‚£ä¸ªç‚¹ç§¯æ“ä½œï¼)\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        # æ± åŒ–å±‚ï¼šé™ç»´ (é€‰æœ€å¤§å€¼)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        # å…¨è¿æ¥å±‚ï¼šåˆ†ç±»\n",
        "        # 28x28 çš„å›¾ç»è¿‡ä¸¤æ¬¡æ± åŒ–(é™¤ä»¥2)ï¼Œå˜æˆ 7x7ã€‚64æ˜¯é€šé“æ•°ã€‚\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
        "        self.fc2 = nn.Linear(128, 10) # è¾“å‡º 10 ä¸ªæ•°å­—çš„æ¦‚ç‡\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Layer 1\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        # Layer 2\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        # Flatten (æ‹‰å¹³æˆä¸€ç»´å‘é‡)\n",
        "        x = x.view(-1, 64 * 7 * 7)\n",
        "        # Fully Connected\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# åˆå§‹åŒ–æ¨¡å‹\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # æœ‰ GPU å°±ç”¨ GPU\n",
        "model = SimpleCNN().to(device)\n",
        "\n",
        "# ==========================================\n",
        "# ç¬¬ä¸‰æ­¥ï¼šå®šä¹‰ä¼˜åŒ–ç›®æ ‡ (Math Setup)\n",
        "# ==========================================\n",
        "# æŸå¤±å‡½æ•° (Loss Function): äº¤å‰ç†µæŸå¤± (CrossEntropy)ï¼Œç”¨æ¥è¡¡é‡â€œçŒœé”™äº†å¤šå°‘â€\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# ä¼˜åŒ–å™¨ (Optimizer): éšæœºæ¢¯åº¦ä¸‹é™ (SGD) çš„è¿›åŒ–ç‰ˆ Adam\n",
        "# lr=0.001 æ˜¯å­¦ä¹ ç‡ (Learning Rate)ï¼Œä¹Ÿå°±æ˜¯æ¢¯åº¦ä¸‹é™çš„æ­¥é•¿\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# ==========================================\n",
        "# ç¬¬å››æ­¥ï¼šå¼€å§‹è®­ç»ƒ (The Training Loop)\n",
        "# ==========================================\n",
        "print(\"ğŸš€ å¼€å§‹è®­ç»ƒ... (å¯èƒ½ä¼šèŠ±å‡ åˆ†é’Ÿ)\")\n",
        "\n",
        "num_epochs = 3 # è®­ç»ƒè½®æ•°ï¼šæŠŠæ‰€æœ‰æ•°æ®çœ‹ 3 é\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # 1. æ¢¯åº¦æ¸…é›¶ (Reset Gradients) - å°±åƒæ•°å­¦æ±‚å¯¼å‰è¦æŠŠä¹‹å‰çš„è®¡ç®—æ¸…ç©º\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 2. å‰å‘ä¼ æ’­ (Forward Pass) - ç®—å‡ºé¢„æµ‹å€¼\n",
        "        outputs = model(images)\n",
        "\n",
        "        # 3. è®¡ç®—è¯¯å·® (Calculate Loss)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # 4. åå‘ä¼ æ’­ (Backward Pass) - è¿™é‡Œçš„æ ¸å¿ƒå°±æ˜¯ Chain Rule (é“¾å¼æ³•åˆ™)ï¼\n",
        "        # å®ƒè®¡ç®—å‡ºæ¯ä¸ªå‚æ•°å¯¹è¯¯å·®çš„è´¡çŒ®(æ¢¯åº¦)\n",
        "        loss.backward()\n",
        "\n",
        "        # 5. æ›´æ–°æƒé‡ (Update Weights) - æ²¿ç€æ¢¯åº¦çš„åæ–¹å‘èµ°ä¸€æ­¥\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if (i+1) % 100 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
        "\n",
        "print(\"âœ… è®­ç»ƒå®Œæˆï¼\")\n",
        "\n",
        "# ==========================================\n",
        "# ç¬¬äº”æ­¥ï¼šæµ‹è¯•å‡†ç¡®ç‡ (Evaluation)\n",
        "# ==========================================\n",
        "model.eval() # åˆ‡æ¢åˆ°æµ‹è¯•æ¨¡å¼\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad(): # æµ‹è¯•ä¸éœ€è¦ç®—æ¢¯åº¦ï¼ŒèŠ‚çœå†…å­˜\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1) # é€‰æ¦‚ç‡æœ€å¤§çš„é‚£ä¸ªæ•°å­—\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'ğŸ‰ åœ¨ 10,000 å¼ æµ‹è¯•å›¾ç‰‡ä¸Šçš„å‡†ç¡®ç‡: {100 * correct / total:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGlqmTXYxXH0",
        "outputId": "089268b9-7fd8-4b40-dda6-4fabd646b28f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9.91M/9.91M [00:00<00:00, 57.1MB/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28.9k/28.9k [00:00<00:00, 1.66MB/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.65M/1.65M [00:00<00:00, 14.6MB/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.54k/4.54k [00:00<00:00, 7.02MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ å¼€å§‹è®­ç»ƒ... (å¯èƒ½ä¼šèŠ±å‡ åˆ†é’Ÿ)\n",
            "Epoch [1/3], Step [100/938], Loss: 0.1576\n",
            "Epoch [1/3], Step [200/938], Loss: 0.0410\n",
            "Epoch [1/3], Step [300/938], Loss: 0.0848\n",
            "Epoch [1/3], Step [400/938], Loss: 0.0462\n",
            "Epoch [1/3], Step [500/938], Loss: 0.0256\n",
            "Epoch [1/3], Step [600/938], Loss: 0.0712\n",
            "Epoch [1/3], Step [700/938], Loss: 0.0113\n",
            "Epoch [1/3], Step [800/938], Loss: 0.0187\n",
            "Epoch [1/3], Step [900/938], Loss: 0.0153\n",
            "Epoch [2/3], Step [100/938], Loss: 0.0414\n",
            "Epoch [2/3], Step [200/938], Loss: 0.0114\n",
            "Epoch [2/3], Step [300/938], Loss: 0.0323\n",
            "Epoch [2/3], Step [400/938], Loss: 0.0078\n",
            "Epoch [2/3], Step [500/938], Loss: 0.0157\n",
            "Epoch [2/3], Step [600/938], Loss: 0.0457\n",
            "Epoch [2/3], Step [700/938], Loss: 0.1176\n",
            "Epoch [2/3], Step [800/938], Loss: 0.0237\n",
            "Epoch [2/3], Step [900/938], Loss: 0.0191\n",
            "Epoch [3/3], Step [100/938], Loss: 0.0051\n",
            "Epoch [3/3], Step [200/938], Loss: 0.1334\n",
            "Epoch [3/3], Step [300/938], Loss: 0.0163\n",
            "Epoch [3/3], Step [400/938], Loss: 0.0148\n",
            "Epoch [3/3], Step [500/938], Loss: 0.0030\n",
            "Epoch [3/3], Step [600/938], Loss: 0.0406\n",
            "Epoch [3/3], Step [700/938], Loss: 0.0055\n",
            "Epoch [3/3], Step [800/938], Loss: 0.0159\n",
            "Epoch [3/3], Step [900/938], Loss: 0.0108\n",
            "âœ… è®­ç»ƒå®Œæˆï¼\n",
            "ğŸ‰ åœ¨ 10,000 å¼ æµ‹è¯•å›¾ç‰‡ä¸Šçš„å‡†ç¡®ç‡: 98.82%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hfX_SAIjzFP2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageOps\n",
        "from google.colab import files\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def predict_my_image():\n",
        "    # 1. å¼¹å‡ºä¸Šä¼ æŒ‰é’®\n",
        "    print(\"è¯·ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®ä¸Šä¼ ä¸€å¼ æ‰‹å†™æ•°å­—å›¾ç‰‡ (ç™½çº¸é»‘å­—)...\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    for filename in uploaded.keys():\n",
        "        # 2. æ‰“å¼€å›¾ç‰‡\n",
        "        image = Image.open(filename)\n",
        "\n",
        "        # 3. å…³é”®æ­¥éª¤ï¼šå›¾ç‰‡é¢„å¤„ç† (è¦æŠŠå›¾ç‰‡å˜å¾—å’Œ MNIST æ•°æ®é›†ä¸€æ ·)\n",
        "        # 3.1 è½¬ä¸ºç°åº¦å›¾ (RGB -> Gray)\n",
        "        img_gray = image.convert('L')\n",
        "\n",
        "        # 3.2 é¢œè‰²åè½¬ï¼(é‡è¦ï¼šå› ä¸º MNIST æ˜¯é»‘åº•ç™½å­—ï¼Œè€Œæˆ‘ä»¬å¹³æ—¶å†™å­—æ˜¯ç™½åº•é»‘å­—)\n",
        "        # å¦‚æœä½ ä¸åè½¬ï¼Œæ¨¡å‹ä¼šæŠŠç™½è‰²èƒŒæ™¯å½“æˆç¬”ç”»ï¼Œç»“æœå°±ä¼šå…¨é”™\n",
        "        img_inverted = ImageOps.invert(img_gray)\n",
        "\n",
        "        # 3.3 è°ƒæ•´å¤§å°ä¸º 28x28\n",
        "        img_resized = img_inverted.resize((28, 28))\n",
        "\n",
        "        # 3.4 è½¬ä¸º Tensor å¹¶å¢åŠ ç»´åº¦ (å˜æˆ [1, 1, 28, 28])\n",
        "        img_tensor = transform(img_resized).unsqueeze(0).to(device)\n",
        "\n",
        "        # 4. è®©æ¨¡å‹é¢„æµ‹\n",
        "        model.eval() # åˆ‡æ¢åˆ°è¯„ä¼°æ¨¡å¼\n",
        "        with torch.no_grad():\n",
        "            output = model(img_tensor)\n",
        "            # è®¡ç®—æ¦‚ç‡ (Softmax)\n",
        "            probabilities = F.softmax(output, dim=1)\n",
        "            prediction = torch.argmax(probabilities, dim=1).item()\n",
        "            confidence = probabilities[0][prediction].item() * 100\n",
        "\n",
        "        # 5. ç”»å‡ºæ¥çœ‹çœ‹\n",
        "        plt.figure(figsize=(4, 4))\n",
        "        plt.imshow(img_resized, cmap='gray')\n",
        "        plt.title(f\"AI Guess: {prediction} ({confidence:.2f}%)\")\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "# è¿è¡Œäº’åŠ¨å‡½æ•°\n",
        "predict_my_image()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "id": "TJvxHgBezFaj",
        "outputId": "3a309462-2607-47ee-a111-9a0d5939ce73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "è¯·ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®ä¸Šä¼ ä¸€å¼ æ‰‹å†™æ•°å­—å›¾ç‰‡ (ç™½çº¸é»‘å­—)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-58444980-6428-4d58-af42-272710cb6886\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-58444980-6428-4d58-af42-272710cb6886\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving image6.jpg to image6.jpg\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x400 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUgAAAFeCAYAAADnm4a1AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAHW5JREFUeJzt3Xlw1PX9x/H3JtmcRBMSAgEKIoaGjhdSg0WhgEGLUZFyDB6jHFo8ULzGaoHKoSKKqFWCB4pXKmpLUFudGlFRGQVFcQYEOYqAIBAtdyTn+/cHw47b5B0+H/BrNv09HzPMlO++9stnN7uvfpPN209IVVUAAPXENfUCACBWUZAAYKAgAcBAQQKAgYIEAAMFCQAGChIADBQkABgoSAAwUJD4n7B582ZJTk6WxYsXN/VSYsIZZ5wht912W1Mvo9mjII9ScXGxhEIh6dGjh5kJhUIyduxYp/PV1dXJc889J/3795fs7GwJh8OSk5Mj55xzjjzxxBNSWVn5Uy09ptTV1cns2bPl1FNPlZSUFMnKypJ+/frJF1984XT/KVOmSI8ePeTMM8+MOv72229L3759JTs7WzIyMqSgoECef/75evffvn27jBw5UnJyciQlJUVOO+00eeWVV5zXv3btWhk+fLi0b99eUlNTJT8/X6ZMmSIVFRX1slVVVXLPPfdIfn6+JCcnS+vWraWoqEi++eabSGbLli1SVFQkxxxzjPzqV7+S119/vd555s+fLzk5ObJ79+56t/3xj3+UWbNmybZt25wfAxqgOCo9e/bU4447TkVE165d22BGRPS666477LkqKir03HPPVRHRnj176rRp0/Tpp5/WGTNm6AUXXKDx8fE6atSon/ohxIQrrrhCExISdNSoUfrkk0/qQw89pFdccYW+9dZbh73vjh07NBwO61//+teo46+++qqGQiHt2bOnPvLII/roo49q7969VUR05syZkdzu3bv1hBNO0PT0dJ0wYUJUrqSk5LD//qZNmzQjI0M7duyo06ZN08cff1xHjBihIqIXXnhhVLaqqkoLCws1NTVVx40bp0899ZTOmDFDhw4dqitWrIjkzj77bM3Pz9fi4mK99NJLNSkpSTds2BC5/YcfftBOnTrp448/3uCaamtrtU2bNjpx4sTDrh82CvIo/Pvf/1YR0fnz52urVq100qRJDeZcC3LMmDEqIvrQQw81ePuaNWt01qxZR7XmWPTSSy9FnscjMXPmTE1JSdG9e/dGHe/fv7+2bdtWDxw4EDlWXV2tnTt31pNPPjly7L777lMR0YULF0aO1dbW6umnn65t2rTRysrKRv/9u+++W0UkquBUVS+//HIVEf3Pf/4TOTZ9+nQNh8O6ZMkS83wVFRUaCoV00aJFqqpaV1ennTp10sceeyySmTp1qp566qlaW1trnmfs2LHasWNHraura3T9sPEt9lEoKSmRzMxMKSoqkiFDhkhJSckRn2vz5s0yZ84c+d3vfifjxo1rMJOXlyfXXntt5O/vvfeehEIhee+996JyX3/9tYRCIXnmmWeijq9evVqGDBkiLVu2lOTkZPn1r38tr732WlSmurpaJk+eLHl5eZKcnCxZWVly1llnSVlZWSSzbds2GTlypLRv316SkpIkNzdXBg4cKF9//XUks3v3blm9enWD3/79t5kzZ0pBQYEMGjRI6urqZP/+/Ye9z48tWLBAevToIS1atIg6vmfPHsnMzJSkpKTIsYSEBMnOzpaUlJTIsQ8++EBatWol/fr1ixyLi4uTYcOGybZt22TRokWN/vt79uwREZHWrVtHHc/NzZW4uDhJTEwUkYM/Rnj44Ydl0KBBUlBQIDU1NQ1+C37gwAFRVcnMzBSRgz+iycjIiGS3bNki9957rzz88MMSF2e/hfv37y8bN26U5cuXN7p+2CjIo1BSUiK///3vJTExUS6++GJZu3atfPLJJ0d0rjfffFNqa2vlsssu+4lXedDKlSvljDPOkFWrVsntt98uDzzwgKSlpclFF10kpaWlkdykSZNk8uTJ0rdvX3n00Udl/Pjx0qFDB/nss88imcGDB0tpaamMHDlSiouL5YYbbpC9e/fKpk2bIpnS0lLp2rVr1LkbsmfPHlm6dKmcfvrp8qc//UmOPfZYadGihRx//PHy8ssvH/ZxVVdXyyeffCKnnXZavdv69OkjK1eulIkTJ8q6detk/fr1MnXqVPn000+jPsCorKyMKsxDUlNTRURk2bJlja6hT58+IiIyevRoWb58uWzevFleeuklmT17ttxwww2SlpYmIiJffvmlbN26VU4++WT5wx/+IGlpaZKWliYnn3yyvPvuu5HzZWZmSufOneWee+6RDRs2SElJiSxfvlwKCgpEROS2226TAQMGSO/evRtdV/fu3UVE+ODqaDT1JWxz9emnn6qIaFlZmaoe/Daoffv2Om7cuHpZcfgW+6abblIR0eXLl0cdr6ys1PLy8sif7777LnLbu+++qyKi7777btR9NmzYoCKic+fOjRw7++yz9aSTTor6drOurk579uypeXl5kWOnnHKKFhUVmevcuXOniojef//9jT6euXPn1ltDQz777DMVEc3KytLWrVtrcXGxlpSUaEFBgYZCIX3zzTcbvf+6detURPSRRx6pd9u+fft02LBhGgqFVERURDQ1NVUXLFgQlbv++us1Li5Ov/7666jjw4cPVxHRsWPHNroG1YPf8qakpET+HRHR8ePHR2Xmz58feax5eXk6d+5cnTt3rubl5WliYqJ+8cUXkezChQs1MzMzcq4bb7xRVVUXL16sKSkp9dZqSUxM1GuuucYpi/ooyCN00003aevWrbWmpiZy7JZbbql3TNWtIEePHq0iouvWrYs6XlpaGvWmS0tLi9zmWpDff/+9hkIhnTp1alTZlpeX6+TJk1VE9JtvvlFV1d/+9rd63HHH6Zo1axpc54EDBzQxMVGLioqifrZ2pN5///3IY/v4448jx/fu3avZ2dl65plnNnr/JUuWqIjoCy+8UO+26upqnTBhgg4dOlRffPFFfeGFF7R3797aokUL/eijjyK5L774QsPhsBYUFOjixYt13bp1es8992hSUpKKiI4ePfqwj+P555/Xc889V5944gn9+9//rqNGjdJQKBRV3M8995yKiCYmJuqmTZsixzdu3KjhcFgvvfTSqHPu3btXP/7440i2trZWu3fvrhMmTFBV1eLiYv3lL3+pXbp00dmzZze4rtatW+vQoUMPu340jII8AjU1NZqbm6vDhw/XtWvXRv68/PLLKiL6r3/9KyrvUpA33nhjg1eQO3bs0LKyMi0rK9NzzjnniAryUIk09uezzz5TVdVFixZpRkaGioieeOKJeuutt0Zd2aiqPvjggxoXF6fhcFh79eql06dP12+//dbnKYz45JNPVES0U6dO9W4bOXKkhsNhra6uNu9/6LE9//zz9W4bM2aMnnLKKVEfZFRVVWleXp4WFBREZV955RXNysqKPB9t2rTR2bNnq4g0+F3Bj7344ouakpKimzdvjjo+YsQITU1NjVz1v/LKKyoi2rdv33rn6Nu3b4PPwY/NmTNH27Vrp/v27dOysjJNS0vT0tJSXbBggaampuo777xT7z45OTk6bNiwRs8LGz+DPALvvPOOfPvttzJv3jzJy8uL/Bk2bJiIyBF9WJOfny8iIitWrIg63qpVKyksLJTCwkLJzc2Nui0UCjV4rtra2qi/19XViYjIrbfeKmVlZQ3+OeGEE0REpHfv3rJ+/Xp5+umn5cQTT5Q5c+bIaaedJnPmzImc78Ybb5Q1a9bItGnTJDk5WSZOnChdu3aVzz//3Ptxt23bVkTqf8AhIpKTkyPV1dWNfmiTlZUlIiI7d+6MOl5VVSVPPfWUFBUVRX2QEQ6HZcCAAfLpp59KVVVV5PiQIUNk69atsnTpUvnoo49k48aNcvzxx4uISJcuXRp9DMXFxdKtWzdp37591PELL7xQKioqIs/L4R7rfz+GH9uzZ4+MHz9e7r33XklLS5MXX3xRhgwZIhdddJEMHDjQ/JBw165dkp2d3ej6YUto6gU0RyUlJZKTkyOzZs2qd9v8+fOltLRUHnvssQZ/8G8ZMGCAxMfHS0lJiVx66aVO9zn0KeeuXbuijm/cuDHq74fe6OFwWAoLCw973pYtW8rIkSNl5MiRsm/fPundu7dMmjRJrrzyykimc+fOcsstt8gtt9wia9eulVNPPVUeeOABeeGFF5zWfkjbtm2lTZs2smXLlnq3bd26VZKTkyU9Pd28f4cOHSQlJUU2bNgQdfz777+Xmpqaev9nIXLwg526urp6tyUmJsrpp58e+fvbb78tInLY52z79u2Rr8V//zsiIjU1NSIictJJJ0k4HDYfa6tWrcx/Y8qUKdKpU6fIa2Pr1q3SrVu3yO1t27at92n1li1bpKqqSrp27dro+tGIpr6EbW4qKio0PT3d/IXtxYsXq4jovHnzIsfE8fcgr7rqKvMDB9WDv1f342+xd+3apfHx8XrTTTdF5QYPHlzvA5I+ffpoy5YtdevWrfXOu2PHjsj//vGHQIcMHTpUs7OzVVV1//79+sMPP0TdXltbq61bt9YhQ4ZErW3VqlW6a9euRh7xQePGjVMRifql8PLycj3mmGP0vPPOO+z9e/Xqpb169Yo6VlNToxkZGdqlS5eo32Pcu3evtm/fXvPz8xs955o1azQ9PV3PP//8qOPl5eW6atUq3b9/f+TY+eefr4mJifrVV19FZS+66CKNi4vTLVu2RI4NHDhQ4+PjddWqVZFjX375pcbHx+u1117b4Fq++uorTUpKivrdySuuuEIHDRoUdd4RI0ZE3e/VV19VEdFly5Y1+lhhoyA9zZs3T0Wk3iehh9TW1mqrVq30ggsuiBxzLcj9+/drYWGhioieeeaZeu+99+rTTz+t9913nw4cOFDj4uK0a9euUfcZPny4JiQk6M0336yzZs3SAQMGaPfu3esV5MqVKzUzM1OzsrL09ttv1yeeeEKnTp2q5513XtQvTR/6mdX06dP1ySef1DFjxmgoFNLrr79eVVU///xzbdmypV599dX6l7/8RYuLi7V///4qIvq3v/0tch7XT7FVVbdt26a5ubmanp6ud955p86cOVO7dOmiKSkp9X4m25AZM2ZoUlKS7t69O+r4XXfdpSKi3bp10wcffFBnzJihXbt2bfBDna5du+qf//xnnTNnjo4fP15btmypHTt2jHx4dcidd95Z7+e+ixYt0vj4eM3JydEpU6ZEvg4ioldeeWXU/VeuXKktWrTQ3NxcnTZtmk6bNk1zc3O1VatW9f6tQ8477zy9/PLLo469/vrrGhcXp3fccYfecccdGhcXp2+88UZUZuzYsdqhQwd+UfwoUJCeLrjgAk1OTo66gvhvI0aM0HA4HLkacy1I1YNXPnPnztV+/fppy5YtNSEhQbOzs/Xss8/Wxx57rN7VW3l5uQ4ePFhTU1M1MzNTx4wZoytWrGiwnNavX6+XX365tmnTRsPhsLZr107PP//8qGK76667tKCgQDMyMjQlJUXz8/P17rvv1qqqKlU9eIV53XXXaX5+vqalpemxxx6rPXr00Jdffjnq3/IpyENrGzRokB5zzDGakpKi/fr106VLlzrdd/v27ZqQkNDgBzWHfmXo0OPp0aNH1OM9ZPjw4fqLX/xCExMTtW3btnr11Vfr9u3b6+UaKkjVgx8WDRgwIPLcdunSRe++++4GP2BatmyZFhYWalpamqanp+vAgQPN3xr45z//qS1atGjwyn/atGnatm1bzc3N1enTp0fdVltbq7m5uZFPvHFkQqrsi43mb/To0bJmzRr54IMPmnopMWHBggVyySWXyPr16+t9uAd3FCT+J2zatEm6dOkiCxcurPdf9Pn/6De/+Y306tVL7rvvvqZeSrNGQQKAgd+DBAADBQkABgoSAAwUJAAYKEgAMDjPYh977LHOJ42FD8aDWsOh//DDT62x/zL00bD+gxY/J581BPX8BsVnvUG9Jn3O29Bs+k+RbW5fN9fnjCtIADBQkABgoCABwEBBAoCBggQAAwUJAAYKEgAMFCQAGChIADBQkABgcB419Bln8hktC2r8KqgRu6BGAn34PLZYGDWMhdHTWODzPPiM7h3aVvanXkNQYuE16arp3+0AEKMoSAAwUJAAYKAgAcBAQQKAgYIEAAMFCQAGChIADBQkABgoSAAwOI8aBqW5jQQGtXtbLIxy+pzX5/n12R3Ph896g1pDUOODsbBLoM/zGx8fH+BK3ATRJVxBAoCBggQAAwUJAAYKEgAMFCQAGChIADBQkABgoCABwEBBAoCBggQAg/OoYSyMEsXC+FVQu8I1t+e3srIykDUkJLhPv/rs5uezXp8xSp/1BjX+2px2CfTV1DukcgUJAAYKEgAMFCQAGChIADBQkABgoCABwEBBAoCBggQAAwUJAAYKEgAMTb6roY+gxvF8drwLag1BjYsF9diKioqcs/3793fO+vjuu++cs+Xl5c7Zjz76yDm7bNky56yPoEYugxLUCK4PdjUEgJ8RBQkABgoSAAwUJAAYKEgAMFCQAGCgIAHAQEECgIGCBAADBQkABud5pv/lndNiYUdBHz7jg8nJyc7ZiRMnOmfPOuss5+zcuXOds++//75ztrq62jl7wgknOGd79erlnF2/fr1zdufOnc5Zn/dbULsl+uxyGQvrDULzWSkA/MwoSAAwUJAAYKAgAcBAQQKAgYIEAAMFCQAGChIADBQkABgoSAAwhNRxO7KsrCznk/rscBbUCGNQ40w+Y36xYPLkyc7Zbt26OWd9xhIXL17snPV5PfiMiPqMJfqM2CUmJjpnw+Gwc9bndRbUjoI+a4iF8UGfr1tlZaVTrukfFQDEKAoSAAwUJAAYKEgAMFCQAGCgIAHAQEECgIGCBAADBQkABgoSAAzOuxr6jBIFNT4Y1EhVULu3+Thw4IBzdujQoc7ZQYMGOWcnTJjgnPXZfTAtLc05GxSfsUSfEbuEBOe3UGBjlD7vC5/XeiyMD/oIYr3N6xkAgJ8RBQkABgoSAAwUJAAYKEgAMFCQAGCgIAHAQEECgIGCBAADBQkABuddDXNycoJey08qFsYSfdbQokUL52xJSYlz9ssvv3TO3nzzzc5ZnxG7WBDUOKlP1mcNPnzOG9QIY1C7fQb1Pv7hhx+cclxBAoCBggQAAwUJAAYKEgAMFCQAGChIADBQkABgoCABwEBBAoCBggQAQyDzYj7jV0GNEvkIagSsurraOVtYWOicTU9Pd84+88wzztnmxmdsLqgROx9Bvc6C2n0wqPUGJYj1cgUJAAYKEgAMFCQAGChIADBQkABgoCABwEBBAoCBggQAAwUJAAYKEgAMgYwaxsL4oA+fMTQfqampzlmfUcMVK1Y4Z1evXu2c9fm6+YxRhsNh56zPbok1NTXO2aDW6zPm5zOCG5Sg3pux8NiCGLnkChIADBQkABgoSAAwUJAAYKAgAcBAQQKAgYIEAAMFCQAGChIADBQkABgCGTX0EdQOiLGw01vHjh2ds3l5ec7ZBx980DnrM+547rnnOmdPOeUU52xOTo5zNiMjwzm7f/9+5+yHH37onH311VedsxUVFc5Zn9ekz2u9uY32NidcQQKAgYIEAAMFCQAGChIADBQkABgoSAAwUJAAYKAgAcBAQQKAgYIEAIPzqKHPzn9BjQ/6jPkFNWpYVVXlnO3WrZtz1mc3vw4dOjhnn332Weesz9jcwoULA8n6jA/6jDD26dPHOdu9e3fn7P333++c/fbbb52zPq8Hn/ebz3soKM1pZ0WuIAHAQEECgIGCBAADBQkABgoSAAwUJAAYKEgAMFCQAGCgIAHAQEECgCGkjnM/7dq1C2QBQY0dBTXCWFNT45wdP368c3bQoEHO2VWrVjlnn3zySefs0qVLnbN79uxxzvrwGRerra11zvq8Hi677DLnbL9+/ZyzEydOdM5u27bNORvUaK8Pn/eQzxqCGB8UcR9p5QoSAAwUJAAYKEgAMFCQAGCgIAHAQEECgIGCBAADBQkABgoSAAwUJAAY3LdO8xALuw/6jCgFtYYTTzzROdupUyfnrM9Oej47CvrsXBkOh52zQY2L+azB5zU5b94852ybNm2cs9dee61zdtKkSc5ZH0HtgOjzHgpqLDEIXEECgIGCBAADBQkABgoSAAwUJAAYKEgAMFCQAGCgIAHAQEECgIGCBABDIKOGQY3uBcVn9CkpKck527FjR+fspk2bnLNvvfWWczYhwf1L7DNq6MPn+Q1KUK/Jp556yjk7ffp052xubq5zduvWrc5Zn1HDWNgtsanX0LyaDAB+RhQkABgoSAAwUJAAYKAgAcBAQQKAgYIEAAMFCQAGChIADBQkABic59B8xtB8Rn5iYee0WPDhhx86Z8vLy52zPqORQY2LxcLOlT6PzWe9FRUVztmdO3c6Z312ufQZU42F3SiDeh8HsV6uIAHAQEECgIGCBAADBQkABgoSAAwUJAAYKEgAMFCQAGCgIAHAQEECgCGQXQ2bG58RpQMHDjhnV69e7Zzdtm2bc9ZHUONiQY0lxoKgnjOf8cFevXo5ZxcuXOic9Rk1bG7Y1RAAfkYUJAAYKEgAMFCQAGCgIAHAQEECgIGCBAADBQkABgoSAAwUJAAYnEcNm9uOdz58Rstqa2uds0uWLHHODhgwwDmbnJzsnI0FQe0+GNTumT7ZjIwM52znzp2ds2+88YZz1mfHUR9NvaOgL3Y1BICfEQUJAAYKEgAMFCQAGChIADBQkABgoCABwEBBAoCBggQAAwUJAAbnUUOfMZ6gRst8xvx8+Iw7JiYmOmdLS0uds4MHD3bO9u/f3zn72muvOWdTUlKcsz7jbT4ja0Hx+RpXVFQ4Zy+++GLn7I4dO5yz//jHP5yzQe1UGNQYsM97vqlHkbmCBAADBQkABgoSAAwUJAAYKEgAMFCQAGCgIAHAQEECgIGCBAADBQkABudRQx9B7YDoM94WC7sw+oyWTZ061Tl75513Omdramqcs2+99ZZz1kdQO975fI2rq6udsz7jg5dccolz9qqrrnLO7ty50zkb1KhhULtGxsIOiK64ggQAAwUJAAYKEgAMFCQAGChIADBQkABgoCABwEBBAoCBggQAAwUJAIaQOs4TdezY0fmkQe1UGNQOZ0HtuufzPFRWVjpn+/bt65wdP368c3bTpk3O2WeffdY5u2rVKufsgQMHnLMZGRnO2VGjRjlnfXaYvOaaa5yzZWVlztmkpCTnbFBiYTdKn/eQT3bv3r1OOa4gAcBAQQKAgYIEAAMFCQAGChIADBQkABgoSAAwUJAAYKAgAcBAQQKAwXnUsFOnTs4n9RlRCmr3waAEtV6fkUufcbx27do5Z2+44Qbn7FlnneWc9RkR9dm5MjU11TnrM0Y5efJk5+z777/vnE1OTnbO+gjqNRkL782gxh13797tlOMKEgAMFCQAGChIADBQkABgoCABwEBBAoCBggQAAwUJAAYKEgAMFCQAGJp81NBHLIxUhUIh56zP+GBQu7fV1NQEks3OznbOdu7c2Tnrs3vm9u3bnbNLlixxzu7bt885m5iY6Jz1GaMM6rXjw+e8QY0X+7zffDBqCABHiYIEAAMFCQAGChIADBQkABgoSAAwUJAAYKAgAcBAQQKAgYIEAEOTjxr67HgX1DhTUKNazW13R5/xNp/H5nNen6yPhISEQM7rI6jXelCjvT6a23jxnj17nHJcQQKAgYIEAAMFCQAGChIADBQkABgoSAAwUJAAYKAgAcBAQQKAgYIEAEMg81c+I1VBCWo3NJ9RuFgYo/QR1NfN52sRDoeds81tnDSocbygXus+z1lQr52mfl80fZMBQIyiIAHAQEECgIGCBAADBQkABgoSAAwUJAAYKEgAMFCQAGCgIAHA0ORbvcXCjmyxsKOgD5/RsuY2lhjUroZB7bQZ1Dgp/DFqCAA/IwoSAAwUJAAYKEgAMFCQAGCgIAHAQEECgIGCBAADBQkABgoSAAyBjBoGNVLlM9blM7LmM7oXHx/vnPURC7vCBcXn+Q1qF7ugvm4+ghpLDOr5Deq14/N183lsQezuyBUkABgoSAAwUJAAYKAgAcBAQQKAgYIEAAMFCQAGChIADBQkABgoSAAwhLS5bekHAD8TriABwEBBAoCBggQAAwUJAAYKEgAMFCQAGChIADBQkABgoCABwPB/4tb1pFESqKoAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}